{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM + CLIP Segmentation Demo\n",
    "This notebook demonstrates open-vocabulary segmentation using SAM and CLIP.\n",
    "You can change image, prompt, grid spacing, and size filtering easily."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Imports\n",
    "import torch\n",
    "from sam_clip.models import load_sam, load_clip\n",
    "from sam_clip.sam_inference import generate_sam_masks\n",
    "from sam_clip.clip_filtering import filter_masks_with_clip"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load models (once)\n",
    "sam_processor, sam_model = load_sam()\n",
    "clip_processor, clip_model = load_clip(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Image path and prompt\n",
    "image_path = '../data/cat.jpeg'  # replace with your image\n",
    "prompt = 'dog sitting on grass'\n",
    "\n",
    "# SAM grid spacing (smaller = more masks, slower)\n",
    "grid_spacing = 50\n",
    "\n",
    "# CLIP filtering\n",
    "clip_threshold = 35  # adjust from 0-100\n",
    "size_mode = 's'      # 's'=small, 'm'=medium, 'l'=large, 'mixed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate SAM Masks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "orig_img, all_masks = generate_sam_masks(\n",
    "    image_path,\n",
    "    sam_processor,\n",
    "    sam_model,\n",
    "    grid_spacing=grid_spacing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter masks with CLIP"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result_img, filtered_masks, scores = filter_masks_with_clip(\n",
    "    orig_img,\n",
    "    all_masks,\n",
    "    text_prompt=prompt,\n",
    "    clip_processor=clip_processor,\n",
    "    clip_model=clip_model,\n",
    "    device=device,\n",
    "    clip_threshold=clip_threshold,\n",
    "    size_mode=size_mode,\n",
    "    preview=True  # show crops interactively\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display final overlay"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result_img.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
